{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch9-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jinukki/KJU/blob/master/Ch9_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D27cn7YBocim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "4e9a0979-3d66-4edd-e5e0-baafaf8bcefd"
      },
      "source": [
        "!pip install tensorflow_gpu==2.00-rc1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_gpu==2.00-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 39kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (1.12.0)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 59.0MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (1.17.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (0.1.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.00-rc1) (3.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==2.00-rc1) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow_gpu==2.00-rc1) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow_gpu==2.00-rc1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow_gpu==2.00-rc1) (0.16.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS9aoUuPojVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e9a6ec0-1ac7-4d5b-816a-a3788a23ecb1"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqnqNSeypDfN",
        "colab_type": "text"
      },
      "source": [
        "## 09-2 순환 신경망을 만들고 텍스트를 분류합니다.\n",
        "#### 텍스트 데이터 변환 방법을 알아보고 앞에서 유도한 경사 하강법 공식으로 순환 신경망 클래스를 구현해 보자.\n",
        "\n",
        "> ### 훈련 세트와 검증 세트를 준비합니다.\n",
        "#### IMDB 데이터 세트는 인터넷 영화 데이터 베이스에서 수집한 영화 리뷰 데이터이다. 순환 신경망으로 이 리뷰들이 긍정적인지 부정적인지 판별해보자. 훈련 세트 25,000개, 테스트 세트 25,000개로 구성되어 있으며 훈련 세트에서 5,000개의 세트를 분리하여 검증 세트로 사용한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-wqNat7o7jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BR6bAbKpLq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train_all, y_train_all), (x_test, y_test)=imdb.load_data(skip_top=20, num_words=100)\n",
        "# skip_top은 가장 많이 등장한 단어들 중 건너뛸 단어의 개수 지정\n",
        "# num_words는 훈련에 사용할 단어의 개수 지정"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g94RGeHApMLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44ed9386-b693-4fa7-a53f-6d73ce7afa19"
      },
      "source": [
        "print(x_train_all.shape, y_train_all.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,) (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEvWEf6VpPUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ecee8101-fe5e-4e56-c127-d9e6898745db"
      },
      "source": [
        "print(x_train_all[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 2, 22, 2, 43, 2, 2, 2, 2, 65, 2, 2, 66, 2, 2, 2, 36, 2, 2, 25, 2, 43, 2, 2, 50, 2, 2, 2, 35, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 39, 2, 2, 2, 2, 2, 2, 38, 2, 2, 2, 2, 50, 2, 2, 2, 2, 2, 2, 22, 2, 2, 2, 2, 2, 22, 71, 87, 2, 2, 43, 2, 38, 76, 2, 2, 2, 2, 22, 2, 2, 2, 2, 2, 2, 2, 2, 2, 62, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 66, 2, 33, 2, 2, 2, 2, 38, 2, 2, 25, 2, 51, 36, 2, 48, 25, 2, 33, 2, 22, 2, 2, 28, 77, 52, 2, 2, 2, 2, 82, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 2, 2, 2, 2, 2, 2, 88, 2, 2, 2, 2, 98, 32, 2, 56, 26, 2, 2, 2, 2, 2, 2, 2, 22, 21, 2, 2, 26, 2, 2, 2, 30, 2, 2, 51, 36, 28, 2, 92, 25, 2, 2, 2, 65, 2, 38, 2, 88, 2, 2, 2, 2, 2, 2, 2, 2, 32, 2, 2, 2, 2, 2, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ3eNpnZpQy8",
        "colab_type": "text"
      },
      "source": [
        "#### 위는 영단어를 고유한 정수에 일대일 대응한 것으로, BoW(Bag of Word) 혹은 어휘 사전이라 부른다. 눈에 띄는 숫자인 2는 사전에 없는 단어를 의미한다. 가장 많이 등장하는 영단어 20개를 건너뛰고 100개 단어만 선택했기 때문에 사전에 없는 영단어가 많다. 추가로 0과 1은 각각 패딩과 글의 시작을 나타내는 데 사용한다. 이 숫자들을 제외하고 훈련 세트를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmMNyZUxpQAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fee18fef-b404-40f4-c383-273c532c4b7d"
      },
      "source": [
        "len(x_train_all)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiMiJyHWpTkL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8fc8e0c7-c637-409e-e2ff-5cbfdb5d5152"
      },
      "source": [
        "for i in range(len(x_train_all)):\n",
        "  x_train_all[i]=[w for w in x_train_all[i] if w>2]\n",
        "\n",
        "print(x_train_all[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22, 43, 65, 66, 36, 25, 43, 50, 35, 39, 38, 50, 22, 22, 71, 87, 43, 38, 76, 22, 62, 66, 33, 38, 25, 51, 36, 48, 25, 33, 22, 28, 77, 52, 82, 36, 71, 43, 26, 46, 88, 98, 32, 56, 26, 22, 21, 26, 30, 51, 36, 28, 92, 25, 65, 38, 88, 32, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK2rD_zzpUri",
        "colab_type": "text"
      },
      "source": [
        "#### 훈련 세트를 영단어로 바꿔보자. 어휘 사전은 get_word_index() 함수로 내려받을 수 있다. 이 함수는 영단어와 정수로 구성된 딕셔너리를 반환한다. 다음은 어휘 사전을 내려받은 다음 딕셔너리 키 값을 movie로 지정하여 값을 출력한 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOHrJnbwpY7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6790b1b3-00c3-42bc-9504-c6082f607509"
      },
      "source": [
        "word_to_index=imdb.get_word_index()\n",
        "word_to_index['movie']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2ANquxeplTx",
        "colab_type": "text"
      },
      "source": [
        "#### 훈련세트에 있는 정수는 3 이상부터 영단어를 의미하므로 3을 뺀 값을 어휘 사전의 인덱스로 사용해야 한다. 훈련 세트를 영단어로 변환하여 출력해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpbKq62spZQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e2be9958-2b95-4f2f-aecc-20851d779635"
      },
      "source": [
        "print(word_to_index['film']) # 훈련 데이터에서 22\n",
        "print(word_to_index['just']) # 훈련 데이터에서 43"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4C1kWkYpoJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "05818f45-43dd-43c8-e581-24d861f71ff1"
      },
      "source": [
        "index_to_word={word_to_index[k]:k for k in word_to_index}\n",
        "\n",
        "for w in x_train_all[0]:\n",
        "  print(index_to_word[w-3], end=' ')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "film just story really they you just there an from so there film film were great just so much film would really at so you what they if you at film have been good also they were just are out because them all up are film but are be what they have don't you story so because all all "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2rSWbw4ppg4",
        "colab_type": "text"
      },
      "source": [
        "#### 훈련 세트 입력 데이터는 넘파이 배열이 아닌 파이썬 리스트이다. 각 리뷰들의 길이가 달라 샘플의 길이가 다르기 때문이다. 두 샘플의 길이를 확인하여 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJfKDRFzpqIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bb5805f-2776-49d9-9476-6fbc1ce4be31"
      },
      "source": [
        "print(len(x_train_all[0]), len(x_train_all[1])) # 샘플별 길이가 다름을 확인"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpH03QrpptWy",
        "colab_type": "text"
      },
      "source": [
        "#### 타깃 데이터도 확인해보자. 이진 분류이므로 타깃 데이터는 1과 0으로 영화 리뷰가 긍정(1)인지 부정(0)인지 나타낸다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0gQ6DVKpwWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f403bb8a-a5b0-4b7c-ad23-f7bd38293884"
      },
      "source": [
        "print(y_train_all[:10])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ2_DmZWpy8U",
        "colab_type": "text"
      },
      "source": [
        "#### 검증 세트를 준비해 보자. 25,000개 훈련 세트 중 5,000개만 분리하여 검증 세이트로 사용하자. 넘파이 premutation() 함수를 이용하여 25,000개의 인덱스를 섞은 후 앞의 20,000개ㅐ는 훈련 세트로, 나머지는 검증 세트로 분리한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b16la6uhpz9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "random_index=np.random.permutation(25000) # 섞은 것을 random.index로 지정\n",
        "\n",
        "x_train=x_train_all[random_index[:20000]]\n",
        "y_train=y_train_all[random_index[:20000]]\n",
        "x_val=x_train_all[random_index[20000:]]\n",
        "y_val=y_train_all[random_index[20000:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7tvQy6_p1DT",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> ### 샘플의 길이 맞추기\n",
        "#### 여기서는 일정 길이가 넘으면 샘플을 잘라버리고 모자라면 0으로 채워 샘플의 길이를 맞추도록 한다. 다음은 샘플의 길이를 7로 맞추기 위해 두 문장을 0으로 채우거나 자른 예이다.\n",
        "\n",
        "#### 길이가 7 이하인 샘플의 왼쪽에 0을 추가했다는 것에 주목하자. 만약 오른쪽에 추가했다면 이후 샘플이 순환 신경망에 주입될 때 0이 마지막에 주입되므로 모델의 성능이 좋지 않을 것이다.\n",
        "\n",
        "#### 텐서플로를 이용해 최대 길이를 100으로 설정하여 길이가 동일한 2개의 넘파이 배열 x_train_seq, x_val_seq를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XYtvV71p3Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "maxlen=100\n",
        "x_train_seq = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val_seq = sequence.pad_sequences(x_val, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tK_repIp6gO",
        "colab_type": "text"
      },
      "source": [
        "#### 훈련 세트의 크기를 확인해보자. 위에서 지정한 값으로 샘플의 길이가 변경되었다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38M2BWN9p7y4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f93c3508-9e76-49d1-8cd8-f0cd53d59a7d"
      },
      "source": [
        "print(x_train_seq.shape, x_val_seq.shape) # 20,000개는 훈련 세트, 5,000개는 검증 세트"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 100) (5000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyeKcSCcp8nQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a01cf724-ad23-4e1a-d93c-05bd7561cf52"
      },
      "source": [
        "print(x_train_seq[0]) # 샘플 길이 변경한 훈련 세트의 첫 번째 샘플 확인(왼쪽에 0으로 채워짐)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 35 40 27 28 40 22 83 31 85 45\n",
            " 24 23 31 70 31 76 30 98 32 22 28 51 75 56 30 33 97 53 38 46 53 74 31 35\n",
            " 23 34 22 58]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNDX1jKqp-wT",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> ### 샘플을 원-핫 인코딩하기\n",
        "#### 훈련 데이터 준비를 위한 마지막 작업은 정수 데이터를 원-핫 인코딩하는 것이다.\n",
        "#### 텐서플로의 to_categorical() 함수를 사용하면 원-핫 인코딩을 손쉽게 처리할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txn4gXPrp9gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "x_train_onehot = to_categorical(x_train_seq)\n",
        "x_val_onehot = to_categorical(x_val_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJWlIW-FqBpS",
        "colab_type": "text"
      },
      "source": [
        "#### 변환시킨 후 크기를 확인하여 보자. 20,000개의 샘플이 100차원으로 원-핫 인코딩되었다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue8ko0WaqArv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "303eb0c8-0a4b-43c8-fc57-3953588c53f6"
      },
      "source": [
        "print(x_train_onehot.shape)\n",
        "print(x_train_onehot[0].shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 100, 100)\n",
            "(100, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad1TKCUwqFN5",
        "colab_type": "text"
      },
      "source": [
        "#### 샘플을 100단어로 제한했지만 크기를 확인해 보면 760MB에 다다른다. 훈련에 사용할 단어의 개수가 늘어나면 컴퓨터의 메모리가 더 필요하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DqLIzCWqCsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a833532-4486-4694-eed8-2da20307f609"
      },
      "source": [
        "print(x_train_onehot.nbytes)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1EqUrJkqHgT",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> ### 순환 신경망 클래스 구현하기\n",
        "#### 이제 06장에서 구현했던 MiniBatchNetwork 클래스를 기반으로 순환 신경망을 파이썬으로 직접 구현해 보자.\n",
        "\n",
        "#### *__*init__() 메서드는 은닉층의 개수 대신 셀 개수를 받는다. 그리고 셀에 필요한 가중치 w1h, w1x를 선언한다. 또 타임 스텝을 거슬러 그레디언트를 전파하려면 순환층의 활성화 출력을 모두 가지고 있어야 하므로 변수 h를 선언한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UwiHPEGqJ7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __init__(self, n_cells=10, batch_size=32, lerning_rate=0.1):\n",
        "  self.n_cells = n_cells       #셀 개수\n",
        "  self.batch_size = batch_size # 배치 크기\n",
        "  self.w1h = None              # 은닉 상태에 대한 가중치\n",
        "  self.w1x = None              # 입력에 대한 가중치\n",
        "  self.b1 = None               # 순환층의 절편\n",
        "  self.w2 = None               # 출력층의 가중치\n",
        "  self.b2 = None               # 출력층의 절편\n",
        "  self.h = None                # 순환층의 활성화 출력\n",
        "  self.losses = []             # 훈련 손실\n",
        "  self.val_losses = []         # 검증 손실\n",
        "  self.lr = lerning_rate       #학습률"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg94tBcQqLGf",
        "colab_type": "text"
      },
      "source": [
        "#### 08장에서 글로럿 초기화 방식으로 가중치를 초기화하며 가중치 초기화의 중요성을 설명하였다. 순환 신경망에서는 직교 행렬 초기화(orthogonal initialization)를 사용한다. 이는 순환 셀에서 은닉 상태를 위한 가중치가 반복해서 곱해질 때 너무 커지거나 작아지지 않도록 만들어준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6_8__t4qQaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(self, n_features, n_classes):\n",
        "  orth_init = tf.initializers.Orthogonal() # 텐서플로가 제공하는 가중치 초기화 클래스 및 직교행렬 초기화 클래스\n",
        "  glorot_init = tf.initializers.GlorotUniform()\n",
        "\n",
        "  self.w1h = orth_init((self.n_cells, self.n_cells)).numpy() # 가중치 값이 초기화된 텐서를 넘파이 배열로 변환하여 가중치 변수에 저장 \n",
        "  self.w1x = glorot_init((n_features, self.n_cells)).numpy()\n",
        "  self.b1 = np.zeros(self.n_cells)\n",
        "  self.w2 = glorot_init((self.n_cells, n_classes)).numpy()\n",
        "  self.b2 = np.zeros(n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cidmKiGbqODZ",
        "colab_type": "text"
      },
      "source": [
        "#### 정방향 계산을 forpass() 메서드에 구현한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK0vZXaqTFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forpass(self, x):\n",
        "  self.h = [np.zeros((x.shape[0], self.n_cells))] # 은닉 상태 초기화"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMgeFY80qTX4",
        "colab_type": "text"
      },
      "source": [
        "#### 각 타임 스텝의 은닉 상태를 저장하기 위해 변수 h를 초기화 한다. 이때 은닉 상태 크기는 (샘플 개수, 셀 개수)이다. 역전파 과정 진행에서 이전 타임 스텝의 은닉 상태를 사용한다. 첫 번째 타임 스텝의 이전 은닉 상태는 없으므로 변수 h의 첫 번째 요소에 0으로 채워진 배열을 추가한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofMCAUvLqUie",
        "colab_type": "text"
      },
      "source": [
        "#### 그런 다음 넘파이의 swapaxes() 함수를 사용하여 입력 x의 배치 차원과 타임 스텝 차원을 바꾼다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cs9pO5tqYg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq=np.swapaxes(x,0,1) # 배치 차원과 타임 스텝 차원을 바꾼다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb_hjsQqqaM2",
        "colab_type": "text"
      },
      "source": [
        "#### 입력 x는 여러 개의 샘플이 담긴 미니 배치이다. 정방향 계산을 할 때는 한 샘플의 모든 타임 스텝을 처리하고 그 다음에 샘플을 처리하는 방식이 아니다. 미니 배치 안에 있는 모든 샘플의 첫 번째 타임 스텝을 한번에 처리하고 두 번째 타임 스텝을 한 번에 처리해야 한다. 이를 손쉽게 구현하기 위해 배치 차원과 타임 스텝 차원을 바꾼 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jMwYZR-qdsr",
        "colab_type": "text"
      },
      "source": [
        "#### 마지막으로 각 샘플의 모든 타임 스텝에 대한 정방향 계산을 수행한다. 셀에서 계산된 은닉 상태는 변수 h에 순서대로 추가된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtgG4bn8qeYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 순환층의 선형식을 계산한다.\n",
        "for x in seq:\n",
        "  z1=np.dot(x, self.w1x) + np.dot(self.h[-1], self.w1h) + self.b1\n",
        "  h=np.tanh(z1)                    # 활성화 함수 적용\n",
        "  self.h.append(h)                 # 역전파를 위한 은닉 상태 저장\n",
        "  z2=np.dot(h, self.w2) + self.b2  # 출력층의 선형식 계산\n",
        "return z2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2n3QKQRqg5p",
        "colab_type": "text"
      },
      "source": [
        "#### 이제 역방향 계산을 backprop() 메서드로 구현해 보자. 여기서도 이 전과 같이 배치 차원과 타임 스텝 차원을 바꾸었다. err_to_cell 변수에 저장되는 값은 $Z_1$ 에 대하여 손실 함수를 미분한 도함수의 결괏값이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k69IO88CqhaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(self, x, err):\n",
        "  m=len(x) # 샘플 개수\n",
        "\n",
        "  # 출력층의 가중치와 절편에 대한 그레디언트 계산\n",
        "  w2_grad = np.dot(self.h[-1].T, err) / m\n",
        "  b2_grad = np.sum(err) / m\n",
        "  # 배치 차원과 타임 스텝 차원을 바꾼다.\n",
        "  seq = np.swapaxes(x, 0, 1)\n",
        "\n",
        "  w1h_grad = w1x_grad = b1_grad = 0 # 초기 0지정\n",
        "  # 셀 직전까지 그레디언트 계산 \n",
        "  err_to_cell = np.dot(err, self.w2.T)*(1-self.h[-1]**2)\n",
        "  # 모든 타임 스텝 거슬러 가며 그레디언트 전파\n",
        "  # 열 번째 까지 진행, h의 마지막 항목은 err_to_cell 정의에 사용하였으므로 제외.\n",
        "  # [A:B:C]코드는 indexA부터 indexB까지 C간격으로 만드는 코드\n",
        "  for x, h in zip(seq[::-1][:10], self.h[:-1][::-1][:10]):\n",
        "    w1h_grad += np.dot(h.T, err_to_cell)\n",
        "    w1x_grad += np.dot(x.T, err_to_cell)\n",
        "    b1_grad += np.sum(err_to_cell, axis=0)\n",
        "    #이전 타임 스텝의 셀 직전까지 그레디언트 계산\n",
        "    err_to_cell = np.dot(err_to_cell, self.w1h)*(1-h**2)\n",
        "\n",
        "  w1h_grad /= m\n",
        "  w1x_grad /= m\n",
        "  b1_grad /= map\n",
        "  \n",
        "  return w1h_grad, w1x_grad, b1_grad, w2_grad, b2_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yGPPD84qjnp",
        "colab_type": "text"
      },
      "source": [
        "#### 딱 10개의 타임 스텝만 거슬러 진행한 이유는 무엇일까? 순환 신경망은 타임 스텝을 거슬러 올라가며 그레디언트를 전파할 때 동일한 가중치를 반복적으로 곱한다. 이로 인해 그레디언트가 너무 커지거나 작아지는 문제가 발생하기 쉽다. 이를 방지하기 위해 그레디언트를 전파하는 타임 스텝의 수를 제한해야 하는데, 이를 TBPTT(Truncated Backpropagation Through Time)라고 부른다. 그 다음 for문에서는 $W_{1h}$의 그레디언트(w1h_grad)를 구하기 위해 $Z_1$에 대한 손실함수의 미분값(err_to_cell)에 다음 식을 곱한다.\n",
        "\n",
        "$$\\frac{\\partial Z_1}{\\partial W_{1h}}=H_{p}+H_{pp}W_{1h}\\odot(1-H_{p}^2)+H_{ppp}W_{1h}\\odot(1-H_{p}^2)\\odot W_{1h}\\odot(1-H_{pp}^2)+\\dots$$\n",
        "\n",
        "#### 타임 스텝이 거슬러 가며 진행될 때마다 err_to_cell에 $W_{1h}\\odot(1-H_{p}^2)$ 형태를 반복해서 곱함으로써 w1h_grad를 구하는 식을 $H$와 err_to_cell 만의 곱으로 단순화시켰다. 마찬가지로 $W_{1x}$의 그레디언트(w1x_grad)와 $b_1$의 그레디언트(b1_grad)도 누적된 err_to_cell 변수를 사용하여 손쉽게 계산 가능하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuHl1KnHqldS",
        "colab_type": "text"
      },
      "source": [
        "#### 순환 신경망, RecurrentNetwork 클래스의 전체 코드는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAlPvloTqm-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RecurrentNetwork:\n",
        "\n",
        "  def __init__(self, n_cells=10, batch_size=32, learning_rate=0.1):\n",
        "    self.n_cells = n_cells       #셀 개수\n",
        "    self.batch_size = batch_size # 배치 크기\n",
        "    self.w1h = None              # 은닉 상태에 대한 가중치\n",
        "    self.w1x = None              # 입력에 대한 가중치\n",
        "    self.b1 = None               # 순환층의 절편\n",
        "    self.w2 = None               # 출력층의 가중치\n",
        "    self.b2 = None               # 출력층의 절편\n",
        "    self.h = None                # 순환층의 활성화 출력\n",
        "    self.losses = []             # 훈련 손실\n",
        "    self.val_losses = []         # 검증 손실\n",
        "    self.lr = learning_rate       #학습률\n",
        "\n",
        "  def forpass(self, x):\n",
        "    self.h = [np.zeros((x.shape[0], self.n_cells))] # 은닉 상태 초기화\n",
        "    seq = np.swapaxes(x, 0, 1) # 배치 차원과 타임 스텝 차원을 바꾼다.\n",
        "    # 순환층의 선형식을 계산한다.\n",
        "    for x in seq:\n",
        "      z1=np.dot(x, self.w1x) + np.dot(self.h[-1], self.w1h) + self.b1\n",
        "      h=np.tanh(z1)                    # 활성화 함수 적용\n",
        "      self.h.append(h)                 # 역전파를 위한 은닉 상태 저장\n",
        "      z2=np.dot(h, self.w2) + self.b2  # 출력층의 선형식 계산\n",
        "    return z2\n",
        "\n",
        "  def backprop(self, x, err):\n",
        "    m=len(x) # 샘플 개수\n",
        "\n",
        "    # 출력층의 가중치와 절편에 대한 그레디언트 계산\n",
        "    w2_grad = np.dot(self.h[-1].T, err) / m\n",
        "    b2_grad = np.sum(err) / m\n",
        "    # 배치 차원과 타임 스텝 차원을 바꾼다.\n",
        "    seq = np.swapaxes(x, 0, 1)\n",
        "\n",
        "    w1h_grad = w1x_grad = b1_grad = 0 # 초기 0지정\n",
        "    # 셀 직전까지 그레디언트 계산 \n",
        "    err_to_cell = np.dot(err, self.w2.T)*(1-self.h[-1]**2)\n",
        "    # 모든 타임 스텝 거슬러 가며 그레디언트 전파\n",
        "    # 열 번째 까지 진행, h의 마지막 항목은 err_to_cell 정의에 사용하였으므로 제외.\n",
        "    # [A:B:C]코드는 indexA부터 indexB까지 C간격으로 만드는 코드\n",
        "    for x, h in zip(seq[::-1][:10], self.h[:-1][::-1][:10]):\n",
        "      w1h_grad += np.dot(h.T, err_to_cell)\n",
        "      w1x_grad += np.dot(x.T, err_to_cell)\n",
        "      b1_grad += np.sum(err_to_cell, axis=0)\n",
        "      #이전 타임 스텝의 셀 직전까지 그레디언트 계산\n",
        "      err_to_cell = np.dot(err_to_cell, self.w1h)*(1-h**2)\n",
        "\n",
        "    w1h_grad /= m\n",
        "    w1x_grad /= m\n",
        "    b1_grad /= m\n",
        "  \n",
        "    return w1h_grad, w1x_grad, b1_grad, w2_grad, b2_grad\n",
        "\n",
        "  def sigmoid(self, z):\n",
        "    a = 1 / (1+np.exp(-z))  # 시그모이드 계산\n",
        "    return a\n",
        "\n",
        "  def init_weights(self, n_features, n_classes):\n",
        "    orth_init = tf.initializers.Orthogonal() # 텐서플로가 제공하는 가중치 초기화 클래스 및 직교행렬 초기화 클래스\n",
        "    glorot_init = tf.initializers.GlorotUniform()\n",
        "\n",
        "    self.w1h = orth_init((self.n_cells, self.n_cells)).numpy() # 가중치 값이 초기화된 텐서를 넘파이 배열로 변환하여 가중치 변수에 저장 \n",
        "    self.w1x = glorot_init((n_features, self.n_cells)).numpy()\n",
        "    self.b1 = np.zeros(self.n_cells)\n",
        "    self.w2 = glorot_init((self.n_cells, n_classes)).numpy()\n",
        "    self.b2 = np.zeros(n_classes)\n",
        "\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None): # x는 훈련 데이터, y는 타깃 데이터\n",
        "    y=y.reshape(-1,1)\n",
        "    y_val=y_val.reshape(-1,1)\n",
        "    np.random.seed(42)\n",
        "    self.init_weights(x.shape[2], y.shape[1])  # 은닉층과 출력층의 가중치 초기화\n",
        "    # epochs만큼 반복한다.\n",
        "    for i in range(epochs):\n",
        "      print(\"에포크\", i, end=' ')\n",
        "      # 제너레이터 함수에서 반환한 미니배치 순환한다.\n",
        "      batch_losses=[]\n",
        "      for x_batch, y_batch in self.gen_batch(x,y):\n",
        "        print('.', end='')\n",
        "        a=self.training(x_batch, y_batch) ## 07장 training 메서드에서 x_val, y_val을 지운다.\n",
        "        # 안전한 로그 계산을 위해 클리핑한다.\n",
        "        a=np.clip(a, 1e-10, 1-1e-10)\n",
        "        # 로그 손실과 규제 손실을 더하여 리스트에 추가한다.\n",
        "        loss=np.mean(-(y_batch*np.log(a) + (1-y_batch)*np.log(1-a)))\n",
        "        batch_losses.append(loss)\n",
        "      print()\n",
        "      self.losses.append(np.mean(batch_losses))\n",
        "      # 검증 세트에 대한 손실 계산\n",
        "      self.update_val_loss(x_val, y_val)\n",
        "\n",
        "  # 미니 배치 제너레이터 함수\n",
        "  def gen_batch(self, x, y):\n",
        "    length = len(x)\n",
        "    bins = length // self.batch_size # 미니 배치 횟수\n",
        "    if length % self.batch_size:\n",
        "      bins += 1                      # 나누어 떨어지지 않을 때 배치 횟수 1추가\n",
        "    indexes=np.random.permutation(np.arange(len(x))) # 인덱스 섞기\n",
        "    x = x[indexes]\n",
        "    y = y[indexes]\n",
        "    for i in range(bins):\n",
        "      start = self.batch_size*i\n",
        "      end = self.batch_size*(i+1)               \n",
        "      yield x[start:end], y[start:end]  # batch_size만큼 슬라이싱하여 반환\n",
        "\n",
        "  def training(self, x, y): ## 07장 training 메서드에서 x_val, y_val을 지운다.\n",
        "    m=len(x)          # 샘플 개수 저장\n",
        "    z=self.forpass(x) # 정방향 계산 수행\n",
        "    a=self.sigmoid(z) # 활성화 함수 저장\n",
        "    err=-(y-a)        # 오차 계산\n",
        "    # 오차를 역전파하여 그레디언트 계산\n",
        "    w1h_grad, w1x_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
        "    # 셀의 가중치와 절편 업데이트\n",
        "    self.w1h -= self.lr*w1h_grad\n",
        "    self.w1x -= self.lr*w1x_grad\n",
        "    self.b1 -= self.lr*b1_grad\n",
        "    # 출력층의 가중치와 절편 업데이트\n",
        "    self.w2 -= self.lr*w2_grad\n",
        "    self.b2 -= self.lr*b2_grad\n",
        "    return a\n",
        "\n",
        "  def predict(self, x):\n",
        "    z=self.forpass(x)  # 정방향 계산 수행\n",
        "    return z>0         # 스텝 함수 적용\n",
        "\n",
        "  def score(self, x, y):\n",
        "    # 예측과 타깃 열 벡터를 비교하여 True의 비율 반환\n",
        "    return np.mean(self.predict(x)==y.reshape(-1,1))\n",
        "\n",
        "  def update_val_loss(self, x_val, y_val):\n",
        "    z=self.forpass(x_val)         # 정방향 계산 수행\n",
        "    a=self.sigmoid(z)             # 활성화 함수 적용\n",
        "    a=np.clip(a, 1e-10, 1-1e-10)  # 출력값 클리핑\n",
        "    val_loss=np.mean(-(y_val*np.log(a) + (1-y_val)*np.log(1-a)))\n",
        "    self.val_losses.append(val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH4GUrYRqs5w",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> ### 순환 신경망 모델 훈련시키기\n",
        "#### 준비한 IDMB 데이터 세트에 RecurrentNetwork 클래스를 적용해 보자.\n",
        "\n",
        "#### 셀 개수는 32개, 배치 크기는 32개, 학습률은 0.01, 에포크 횟수는 20을 사용한다. 이런 값을 포함해 TBPTT를 위한 타임 스텝 횟수는 모두 하이퍼 파라미터이다. 데이터 세트에 따라 반복적인 실험을 통해 적절한 값을 찾아야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNsKV_XBqqm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "bd32f01c-d241-402e-d02c-53fa92f83e1f"
      },
      "source": [
        "rn = RecurrentNetwork(n_cells=32, batch_size=32, learning_rate=0.01)\n",
        "\n",
        "rn.fit(x_train_onehot, y_train, epochs=20, x_val=x_val_onehot, y_val=y_val)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크 0 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 1 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 2 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 3 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 4 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 5 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 6 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 7 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 8 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 9 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 10 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 11 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 12 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 13 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 14 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 15 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 16 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 17 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 18 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 19 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzJuABZQquPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1df53bb0-4750-4834-dea1-04d93d1bc1f6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(rn.losses, color='red', label=\"losses\")\n",
        "plt.plot(rn.val_losses, color='green', label=\"val_losses\")\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OQ3ZdKVrjoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b7ba88e-3e50-4d49-ac46-1c8a2ff7499a"
      },
      "source": [
        "rn.score(x_val_onehot, y_val) # 검증 세트 정확도 평가"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6054"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6C7r_71sUSY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "a7862b08-d997-426b-96c7-8e21031bd3cd"
      },
      "source": [
        "# epochs=10으로 재설정\n",
        "\n",
        "rn = RecurrentNetwork(n_cells=32, batch_size=32, learning_rate=0.01)\n",
        "\n",
        "rn.fit(x_train_onehot, y_train, epochs=10, x_val=x_val_onehot, y_val=y_val)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크 0 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 1 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 2 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 3 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 4 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 5 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 6 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 7 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 8 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 9 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coweF-6BsmOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5c169149-17c2-4629-e855-d28469014700"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(rn.losses, color='red', label=\"losses\")\n",
        "plt.plot(rn.val_losses, color='green', label=\"val_losses\")\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYzbInFNs1SK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d122a6d2-7f19-43a9-f96c-7627774a36e6"
      },
      "source": [
        "rn.score(x_val_onehot, y_val)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzgSkTyytNTH",
        "colab_type": "text"
      },
      "source": [
        "#### 영화 리뷰가 긍정인지 부정인지를 무작위로 예측하는 확률(50%)보다는 좋은 성능이 나왔다. 하지만 실전에 투입하기에는 조금 아쉬운 성능이다. 다음 절에서 텐서플로를 사용해 여러 고급 기술을 사용한 순환 신경망을 만들어 볼 것이다."
      ]
    }
  ]
}