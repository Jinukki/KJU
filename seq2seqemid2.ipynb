{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seqemid2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jinukki/KJU/blob/master/seq2seqemid2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9wUjdMEF80x",
        "colab_type": "text"
      },
      "source": [
        "##### 앞서 배운 seq2seq 모델은 인코더에서 입력 시퀀스를 컨텍스트 벡터라는 하나의 고정된 크기의 벡터 표현으로 압축하고, 디코더는 이 컨텍스트 벡터를 통해서 출력 시퀀스를 만들어냈다.\n",
        "\n",
        "##### 하지만 이러한 RNN에 기반한 seq2seq 모델에는 크게 두 가지 문제가 있다.<br>\n",
        "첫째, 하나의 고정된 크기의 벡터에 모든 정보를 압축하려고 하니까 정보 손실이 발생한다.<br>\n",
        "둘째, RNN의 고질적인 문제인 기울기 소실(Vanishing Gradient) 문제가 존재한다.\n",
        "\n",
        "##### 즉, 결국 이는 기계 번역 분야에서 입력 문장이 길면 번역 품질이 떨어지는 현상으로 나타났다. 이를 위한 대안으로 입력 시퀀스가 길어지면 출력 시퀀스의 정확도가 떨어지는 것을 보정해주기 위한 등장한 기법인 어텐션(attention)을 소개할 것이다.\n",
        "\n",
        "> ##### 어텐션의 아이디어\n",
        "##### 어텐션의 기본 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점이다. 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)해서 보게 된다.\n",
        "\n",
        "##### 어텐션 모델은 처음에는 sequence to sequence context vector 를 개선하기 위하여 제안되었지만, 이제는 다양한 딥러닝 모델링에 하나의 기술로 이용되고 있다. 물론 모델의 성능을 향상 시킨 점도 크지만, 부산물로 얻을 수 있는 attention weight matrix 를 이용한 모델의 작동 방식에 대한 시각화는 모델의 안정성을 점검하고, 모델이 의도와 다르게 작동할 때 그 원인을 찾는데 이용될 수 있다. 이전보다 쉽게 복잡한 모델들을 해석할 수 있게 된 것이다.\n",
        "\n",
        "###### 아래 그림처럼 디코더 RNN이 $y_i$를 선택할 때 encoder RNN의 $h_j$를 얼만큼 이용할지를 $a_ij$로 정의한다. $a_ij$를 attention weight 라 하며, 이 역시 neural network 에 의하여 학습된다.\n",
        "\n",
        "![어텐션 1](https://user-images.githubusercontent.com/52277776/70718298-4e27f300-1d33-11ea-93cd-a740587edb97.png)\n",
        "\n",
        "##### 즉 이전에는 아래의 그림처럼 ‘this is example sentence’ 를 ‘이것은 예문이다’로 번역하기 위하여 매번 같은 context vector 를 이용했지만, \n",
        "\n",
        "![어텐션 2](https://user-images.githubusercontent.com/52277776/70718308-5122e380-1d33-11ea-80c2-891304cdf872.png)\n",
        "\n",
        "##### attention 이 이용되면서 ‘이것’ 이라는 단어를 선택하기 위하여 ‘this is’ 라는 부분에 주목할 수 있게 되었다.\n",
        "\n",
        "![어텐션 3](https://user-images.githubusercontent.com/52277776/70718314-52eca700-1d33-11ea-96ad-347ceffd9c9d.png)\n",
        "\n",
        "##### 그리고 그 결과물로 attention weight matrix 를 얻을 수 있다. 아래는 영어와 프랑스어 간에 번역을 위하여 각각 어떤 단어끼리 높은 attention weight 가 부여됬는지를 표현한 그림이다. 검정색일수록 낮은 weight 를 의미한다. 관사끼리는 서로 연결이 되어 있으며, 의미가 비슷한 단어들이 실제로 높은 attention weight 를 얻는다. 그리고 하나의 단어가 두 개 이상의 단어의 정보를 조합하여 이용하기도 한다.\n",
        "\n",
        "##### 하지만 대체로 한 단어 $y_i$를 만들기 위하여 이용되는 $h_j$ 의 개수는 그리 많지 않다. 이는 decoder 가 context 를 선택적으로 이용하고 있다는 의미이다. 그럼에도 불구하고 기존의 sequence to sequence 에서는 하나의 벡터에 이 모든 정보를 표현하려 했으니, RNN 의 모델의 크기는 커야했고 성능도 낮을 수 밖에 없었다. Attention mechanism 은 같은 크기의 공간을 이용하는 RNN 이라면 더 좋은 성능을 보이도록 도와주었다. RNN 은 sequence encoding 을, attention 은 context vector 를 만드는 일을 서로 나눴다. 하나의 네트워크에 하나의 일만 맡기는 것은 네트워크에 부하를 줄여주는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGSv5XCxMWc5",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "##### 단뱡항 LSTM으로 텍스트 분류를 수행할 수도 있지만 때로는 양방향 LSTM을 사용하는 것이 더 강력하다. 여기에 추가적으로 어텐션 메커니즘을 사용할 수도 있다. 양방향 LSTM과 어텐션 메커니즘으로 지난 발표에서 진행했던 IMDB 리뷰 감성 분류하기를 수행해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiB2sp0TMmA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "08ca9073-01a4-4a93-b521-f8f9d220962e"
      },
      "source": [
        "try:\n",
        "\n",
        "    %tensorflow_version 2.x  # %tensorflow_version only exists in Colab\n",
        "\n",
        "except Exception:\n",
        "\n",
        "    pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.x  # %tensorflow_version only exists in Colab`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnyQRR3HL2iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHWqzj3wMgeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000 # 최대 단어 개수 100개\n",
        "# 훈련데이터와 테스트데이터 받아오기\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGG14Wt3Moya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1ba5e740-9f60-4688-84f8-d026a729ebe6"
      },
      "source": [
        "# 패딩을 위한 리뷰의 최대 길이와 평균길이 확인\n",
        "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
        "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 2494\n",
            "리뷰의 평균 길이 : 238.71364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5YnT0znMwMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 평균길이보도 조금 더 크게 패딩\n",
        "max_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyw1H9PxNB9y",
        "colab_type": "text"
      },
      "source": [
        "##### 이제 어텐션 메커니즘을 적용해 보자. 다시 말하자면 RNN의 모든 은닉 상태들을 다시 한 번 참고하겠다는 것이다. 그리고 이를 위해서 어텐션 메커니즘을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J32zMTHHM7xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VMIKplzNtR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, BatchNormalization\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnUn_tVYN8O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # warining 표시 안나오도록 하기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ-HH-8XN9kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력층과 임베딩층 설계\n",
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "# 10,000개의 단어들을 128차원의 임베딩 벡터로 임베딩하도록 설계\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len)(sequence_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRhXlFFmOB6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
        "    (LSTM(128, dropout=0.3, return_sequences=True, return_state=True, recurrent_activation='relu', recurrent_initializer='glorot_uniform'))(embedded_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HbuEZ5HOT2w",
        "colab_type": "text"
      },
      "source": [
        "##### 양방향 LSTM을 설계하였다. 순방향 LSTM의 은닉 상태와 셀상태를 forward_h, forward_c에 저장하고, 역방향 LSTM의 은닉 상태와 셀 상태를 backward_h, backward_c에 저장합니다. 양방향 LSTM을 사용할 경우에는 순방향 LSTM과 역방향 LSTM 각각 은닉 상태와 셀 상태를 가지므로, 양방향 LSTM의 은닉 상태와 셀 상태를 사용하려면 두 방향의 LSTM의 상태들을 연결(concatenate)해주면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wsz6LQEODbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ZSSZA6Obtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention = BahdanauAttention(128) # 가중치 크기 정의\n",
        "# 어텐션 매커니즘에서는 은닉 상태 사용, 이를 입력으로 컨텍스트 벡터 얻음\n",
        "context_vector, attention_weights = attention(lstm, state_h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6A71KiyOi03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention = BahdanauAttention(128) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPw_ttrTOlVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden = BatchNormalization()(context_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWsjV47YOl1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이진출력이므로 Dense에 1개의 층 & 시그모이드 활성화 함수 사용\n",
        "output = Dense(1, activation='sigmoid')(hidden)\n",
        "model = Model(inputs=sequence_input, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJPcr6nzOsBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adam = optimizers.Adam(lr=0.0001, clipnorm=1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8trEFyHPPN_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc2xuGroPOyp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "a6d38f10-4e1c-4d0f-9a5b-2b9c80e97c94"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test), verbose=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 291s 12ms/sample - loss: 0.4526 - accuracy: 0.7898 - val_loss: 0.3946 - val_accuracy: 0.8408\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 291s 12ms/sample - loss: nan - accuracy: 0.6140 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 289s 12ms/sample - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 293s 12ms/sample - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 293s 12ms/sample - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 291s 12ms/sample - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 292s 12ms/sample - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 291s 12ms/sample - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 291s 12ms/sample - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 300s 12ms/sample - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJy-GeTUREPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "453393fc-dc89-4cd9-adf8-3818869647ec"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'], color='red')\n",
        "plt.plot(history.history['val_accuracy'], color='green')\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gykoHbPlmAL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}